{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "PATH = 'C:/Users/danie/Documents/U/6to Semestre/Inteligencia Artificial/3er Corte/PLN'\n",
    "DIR_DATA = '..//Inteligencia Artificial/3er Corte/PLN/data/input/'\n",
    "sys.path.append(PATH) if PATH not in list(sys.path) else None\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, log_loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "\n",
    "from logic.utils import Utils\n",
    "from logic.classifiers import Classifiers\n",
    "from logic.text_processing import TextProcessing\n",
    "from logic.lexical_vectorizer import LexicalVectorizer\n",
    "from root import DIR_RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'es'\n",
    "iteration = 10\n",
    "fold = 10\n",
    "classifiers = Classifiers.dict_classifiers\n",
    "tp = TextProcessing(lang=lang)\n",
    "lv = LexicalVectorizer(lang=lang, text_processing=tp)\n",
    "ut = Utils(lang=lang, text_processing=tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Import training...\n",
      "\t\t - Dataset size :(x: 5886 , y: 5886)\n",
      "+ Import test...\n",
      "\t\t - Dataset size :(x: 857 , y: 857)\n"
     ]
    }
   ],
   "source": [
    "print('+ Import training...')\n",
    "x, y = ut.get_data(file_name='tass2020_emotion_train')\n",
    "print('+ Import test...')\n",
    "x_eval, y_eval = ut.get_data(file_name='tass2020_emotion_dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train:\n",
      " [('anger ', 600), ('disgust ', 113), ('fear ', 67), ('joy ', 1270), ('others', 1), ('others ', 2888), ('sadness ', 706), ('surprise ', 241)]\n",
      "- test: \n",
      " [('anger ', 87), ('disgust ', 16), ('fear ', 10), ('joy ', 185), ('others ', 421), ('sadness ', 103), ('surprise ', 35)]\n"
     ]
    }
   ],
   "source": [
    "x = lv.transform(x)\n",
    "x_eval = lv.transform(x_eval)\n",
    "print('- train:\\n', sorted(Counter(y).items()))\n",
    "print('- test: \\n', sorted(Counter(y_eval).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train:\n",
      " [('anger ', 2022), ('disgust ', 2022), ('fear ', 2022), ('joy ', 2022), ('others', 2022), ('others ', 2022), ('sadness ', 2022), ('surprise ', 2022)]\n",
      "- test:\n",
      " [('anger ', 866), ('disgust ', 866), ('fear ', 866), ('joy ', 866), ('others ', 866), ('sadness ', 866), ('surprise ', 866)]\n"
     ]
    }
   ],
   "source": [
    "k_fold = ShuffleSplit(n_splits=fold, test_size=0.25, random_state=42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=42)\n",
    "ros_train = RandomOverSampler(random_state=1000)\n",
    "x_train, y_train = ros_train.fit_resample(x_train, y_train)\n",
    "x_test, y_test = ros_train.fit_resample(x_test, y_test)\n",
    "print('- train:\\n', sorted(Counter(y_train).items()))\n",
    "print('- test:\\n', sorted(Counter(y_test).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory)\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mgca()\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(12, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
